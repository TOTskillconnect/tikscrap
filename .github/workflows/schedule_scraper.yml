name: Scheduled TikTok Scraper

on:
  schedule:
    # Run daily at 03:00 UTC
    - cron: '0 3 * * *'
  workflow_dispatch:  # Allows manual triggering with the "Run workflow" button

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          
      - name: Copy requirements file to root
        run: |
          if [ -f "tiktok-niche-scraper/requirements.txt" ]; then
            cp tiktok-niche-scraper/requirements.txt .
            echo "Copied requirements file from tiktok-niche-scraper directory"
          elif [ -f "requirements.txt" ]; then
            echo "Requirements file already exists in root directory"
          else
            echo "Error: Could not find requirements.txt in either location"
            exit 1
          fi
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f "requirements.txt" ]; then
            pip install -r requirements.txt
          elif [ -f "tiktok-niche-scraper/requirements.txt" ]; then
            pip install -r tiktok-niche-scraper/requirements.txt
          else
            echo "Error: Could not find requirements.txt"
            exit 1
          fi
          
          # Skip browser installation completely for GitHub Actions
          export PLAYWRIGHT_SKIP_BROWSER_DOWNLOAD=1
          
          # Create directories Playwright would look for
          mkdir -p $HOME/.cache/ms-playwright
          
          # Install minimal system dependencies that are known to be available
          echo "Installing only essential system dependencies"
          sudo apt-get update
          sudo apt-get install -y \
            fonts-liberation \
            libnss3 \
            libatk1.0-0 \
            libatk-bridge2.0-0 \
            libcups2 \
            libdrm2 \
            libxkbcommon0 \
            xvfb
            
          # Force NO_BROWSER mode for the script
          echo "NO_BROWSER=1" >> $GITHUB_ENV
          echo "Using NO_BROWSER mode to avoid browser dependency issues"
        
      - name: Set up Google credentials
        if: ${{ github.event_name != 'pull_request' }}
        run: |
          cd tiktok-niche-scraper
          if [ -n "${{ secrets.GOOGLE_CREDENTIALS_JSON }}" ]; then
            echo "${{ secrets.GOOGLE_CREDENTIALS_JSON }}" > credentials.json
            echo "Google credentials configured"
          else
            echo "No Google credentials provided, skipping Google Sheets integration"
          fi
        shell: bash
          
      - name: Ensure data directory exists
        run: |
          mkdir -p tiktok-niche-scraper/data
          
      - name: Run scraper
        run: |
          cd tiktok-niche-scraper
          # We're using NO_BROWSER from environment variables already set earlier
          echo "Running scraper with NO_BROWSER=$NO_BROWSER"
          python main.py
        
      # Commit and push any new data files back to the repository
      - name: Commit and push if there are changes
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add tiktok-niche-scraper/data/
          git diff --quiet && git diff --staged --quiet || git commit -m "Add scraped data [automated]"
          git push
