name: Scheduled TikTok Scraper

on:
  schedule:
    # Run daily at 03:00 UTC
    - cron: '0 3 * * *'
  workflow_dispatch:  # Allows manual triggering with the "Run workflow" button

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          
      - name: Copy requirements file to root
        run: |
          if [ -f "tiktok-niche-scraper/requirements.txt" ]; then
            cp tiktok-niche-scraper/requirements.txt .
            echo "Copied requirements file from tiktok-niche-scraper directory"
          elif [ -f "requirements.txt" ]; then
            echo "Requirements file already exists in root directory"
          else
            echo "Error: Could not find requirements.txt in either location"
            exit 1
          fi
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          
          # Modify requirements installation to exclude playwright
          if [ -f "requirements.txt" ]; then
            # Install all requirements EXCEPT playwright
            grep -v "playwright" requirements.txt > requirements_no_browser.txt
            pip install -r requirements_no_browser.txt
          elif [ -f "tiktok-niche-scraper/requirements.txt" ]; then
            # Install all requirements EXCEPT playwright
            grep -v "playwright" tiktok-niche-scraper/requirements.txt > requirements_no_browser.txt
            pip install -r requirements_no_browser.txt
          else
            echo "Error: Could not find requirements.txt"
            exit 1
          fi
          
          # Install only minimal packages needed without browser
          pip install requests beautifulsoup4 pandas
          
          # Force NO_BROWSER environment variable for the entire workflow
          echo "NO_BROWSER=1" >> $GITHUB_ENV
        
      - name: Set up Google credentials
        if: ${{ github.event_name != 'pull_request' }}
        run: |
          cd tiktok-niche-scraper
          if [ -n "${{ secrets.GOOGLE_CREDENTIALS_JSON }}" ]; then
            echo "${{ secrets.GOOGLE_CREDENTIALS_JSON }}" > credentials.json
            echo "Google credentials configured"
          else
            echo "No Google credentials provided, skipping Google Sheets integration"
          fi
        shell: bash
          
      - name: Ensure data directory exists
        run: |
          mkdir -p tiktok-niche-scraper/data
          chmod -R 777 tiktok-niche-scraper/data
          echo "Created data directory with full permissions"
          
      - name: Run scraper
        run: |
          cd tiktok-niche-scraper
          # We're using NO_BROWSER environment variable set earlier
          echo "Running scraper with NO_BROWSER=1"
          python main.py
        
      # Commit and push any new data files back to the repository
      - name: Commit and push if there are changes
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add tiktok-niche-scraper/data/
          git diff --quiet && git diff --staged --quiet || git commit -m "Add scraped data [automated]"
          git push
